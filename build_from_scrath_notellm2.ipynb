{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境包导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先导入基础包\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# 1. 导入所需的包\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    LlavaForConditionalGeneration,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from modelscope import snapshot_download\n",
    "from custom_llava import CustomLlavaModel\n",
    "from micl_model import MICLModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MICLDataset(Dataset):\n",
    "    \"\"\"MICL数据集类\"\"\"\n",
    "    def __init__(self, json_path, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        Args:\n",
    "            json_path: JSON文件路径\n",
    "            image_dir: 图片目录路径\n",
    "            transform: 图像转换函数\n",
    "        \"\"\"\n",
    "        self.data = self.load_data(json_path, image_dir)\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(json_path, image_dir):\n",
    "        \"\"\"加载数据集\"\"\"\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        dataset = []\n",
    "        for item in data:\n",
    "            q=[]\n",
    "            image_path = os.path.join(image_dir, item['query']['image_name'])\n",
    "            if os.path.exists(image_path):\n",
    "                q.append({\n",
    "                    'image': image_path,\n",
    "                    'topic': item['query']['keywords'],\n",
    "                    'comment': item['query']['comment']\n",
    "                })\n",
    "            t=[]\n",
    "            image_path = os.path.join(image_dir, item['target']['image_name'])\n",
    "            if os.path.exists(image_path):\n",
    "                t.append({\n",
    "                    'image': image_path,\n",
    "                    'topic': item['target']['keywords'],\n",
    "                    'comment': item['target']['comment']\n",
    "                })\n",
    "            dataset.append({\n",
    "                'query': q,\n",
    "                'target': t\n",
    "            })\n",
    "        return dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集大小\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取单个数据样本\"\"\"\n",
    "        item = self.data[idx]\n",
    "\n",
    "        # 处理查询图像\n",
    "        query_image = self.transform(item['query'][0]['image'])\n",
    "        query_topic = item['query'][0]['topic']\n",
    "        query_comment = item['query'][0]['comment']\n",
    "\n",
    "        # 处理目标图像\n",
    "        target_image = self.transform(item['target'][0]['image'])\n",
    "        target_topic = item['target'][0]['topic']\n",
    "        target_comment = item['target'][0]['comment']\n",
    "\n",
    "        return {\n",
    "            'query_image': query_image,\n",
    "            'query_topic': query_topic,\n",
    "            'query_comment': query_comment,\n",
    "            'target_image': target_image,\n",
    "            'target_topic': target_topic,\n",
    "            'target_comment': target_comment\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': [{'image': '/root/course/llava/data/img200/1000344755.jpg',\n",
       "    'topic': 'man blue,standing stair,cleaning windows',\n",
       "    'comment': 'Someone in a blue shirt and hat is standing on stair and leaning against a window . A man in a blue shirt is standing on a ladder cleaning a window . A man on a ladder cleans the window of a tall building . man in blue shirt and jeans on ladder cleaning windows a man on a ladder cleans a window'}],\n",
       "  'target': [{'image': '/root/course/llava/data/img200/1044798682.jpg',\n",
       "    'topic': 'man stands,scaffolding,cleaning windows',\n",
       "    'comment': 'A man wearing a hat and a white shirt is cleaning windows . A man in a white shirt stands high up on scaffolding A man stands on boards on top of a huge ladder . Man works on top of scaffolding . A guy works on a building .'}]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "json_path = 'data/caption_key3_sim_bey25.json'\n",
    "image_dir = '/root/course/llava/data/img200/'\n",
    "dataset = MICLDataset.load_data(json_path, image_dir)\n",
    "\n",
    "\n",
    "dataset[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class DataProcessor(nn.Module):\n",
    "    \"\"\"\n",
    "    数据处理器类，用于处理MICL数据集的图像和文本\n",
    "    结合了AutoProcessor的功能来处理多模态输入\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, processor, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "        self.device = device  # 添加设备参数\n",
    "                # 设置处理器的patch_size\n",
    "        self.processor.patch_size = 14  # LLaVA默认使用14x14的patch size\n",
    "        self.processor.num_additional_image_tokens = 1\n",
    "        self.processor.vision_feature_select_strategy = \"default\"\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取单个数据样本\"\"\"\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        # 打开图像文件\n",
    "        query_image = Image.open(item['query'][0]['image']).convert('RGB')\n",
    "        target_image = Image.open(item['target'][0]['image']).convert('RGB')\n",
    "\n",
    "        # 构建查询提示\n",
    "        prompt_q = f\"Note content: {{'topic': '{item['query'][0]['topic']}', 'content': '{item['query'][0]['comment']}', 'image': <image>}}, Compress this note into one word：\"\n",
    "\n",
    "        # 构建目标提示\n",
    "        prompt_t = f\"Note content: {{'topic': '{item['target'][0]['topic']}', 'content': '{item['target'][0]['comment']}', 'image': <image>}}, Compress this note into one word：\"\n",
    "\n",
    "        # 处理查询输入\n",
    "        input_q = self.processor(\n",
    "            images=query_image,\n",
    "            text=prompt_q,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "\n",
    "        # 处理目标输入\n",
    "        input_t = self.processor(\n",
    "            images=target_image,\n",
    "            text=prompt_t,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "\n",
    "        # 移除批次维度\n",
    "        for k in input_q.keys():\n",
    "            if torch.is_tensor(input_q[k]):\n",
    "                input_q[k] = input_q[k].squeeze(0)\n",
    "        for k in input_t.keys():\n",
    "            if torch.is_tensor(input_t[k]):\n",
    "                input_t[k] = input_t[k].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            'query_inputs': input_q,\n",
    "            'target_inputs': input_t\n",
    "        }\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        将多个样本组合成一个批次\n",
    "        Args:\n",
    "            batch: 样本列表\n",
    "        Returns:\n",
    "            批处理后的数据\n",
    "        \"\"\"\n",
    "        # 初始化批次数据结构\n",
    "        batch_data = {\n",
    "            'query_inputs': {\n",
    "                'input_ids': [],\n",
    "                'attention_mask': [],\n",
    "                'pixel_values': []\n",
    "            },\n",
    "            'target_inputs': {\n",
    "                'input_ids': [],\n",
    "                'attention_mask': [],\n",
    "                'pixel_values': []\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # 首先收集所有序列长度\n",
    "        max_length = {\n",
    "            'query_inputs': {'input_ids': 0, 'attention_mask': 0},\n",
    "            'target_inputs': {'input_ids': 0, 'attention_mask': 0}\n",
    "        }\n",
    "\n",
    "        # 找出最大长度\n",
    "        for sample in batch:\n",
    "            for input_type in ['query_inputs', 'target_inputs']:\n",
    "                max_length[input_type]['input_ids'] = max(\n",
    "                    max_length[input_type]['input_ids'],\n",
    "                    len(sample[input_type]['input_ids'])\n",
    "                )\n",
    "                max_length[input_type]['attention_mask'] = max(\n",
    "                    max_length[input_type]['attention_mask'],\n",
    "                    len(sample[input_type]['attention_mask'])\n",
    "                )\n",
    "\n",
    "        # 收集并padding数据\n",
    "        for sample in batch:\n",
    "            for input_type in ['query_inputs', 'target_inputs']:\n",
    "                # 处理input_ids\n",
    "                input_ids = sample[input_type]['input_ids']\n",
    "                padding_length = max_length[input_type]['input_ids'] - len(input_ids)\n",
    "                padded_input_ids = torch.cat([\n",
    "                    input_ids,\n",
    "                    torch.zeros(padding_length, dtype=input_ids.dtype)\n",
    "                ])\n",
    "                batch_data[input_type]['input_ids'].append(padded_input_ids)\n",
    "\n",
    "                # 处理attention_mask\n",
    "                attention_mask = sample[input_type]['attention_mask']\n",
    "                padding_length = max_length[input_type]['attention_mask'] - len(attention_mask)\n",
    "                padded_attention_mask = torch.cat([\n",
    "                    attention_mask,\n",
    "                    torch.zeros(padding_length, dtype=attention_mask.dtype)\n",
    "                ])\n",
    "                batch_data[input_type]['attention_mask'].append(padded_attention_mask)\n",
    "\n",
    "                # 处理pixel_values (图像特征通常已经是固定大小)\n",
    "                batch_data[input_type]['pixel_values'].append(sample[input_type]['pixel_values'])\n",
    "\n",
    "        # 堆叠张量并移动到指定设备\n",
    "        for input_type in ['query_inputs', 'target_inputs']:\n",
    "            for key in batch_data[input_type].keys():\n",
    "                batch_data[input_type][key] = torch.stack(batch_data[input_type][key]).to(self.device)\n",
    "\n",
    "        return batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型本地导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /root/.cache/modelscope/hub/swift/llava-1.5-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 18:11:54,269 - modelscope - INFO - Target directory already exists, skipping creation.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dir = snapshot_download('swift/llava-1.5-7b-hf')\n",
    "# 2. 配置显存优化参数\n",
    "torch.cuda.empty_cache()  # 清空显存缓存\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "\n",
    "# 3. 配置量化参数（更激进的量化）\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                     # 启用 4-bit 量化\n",
    "    bnb_4bit_quant_type=\"nf4\",            # 使用 NF4 量化类型\n",
    "    bnb_4bit_use_double_quant=True,       # 启用双量化\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # 使用 float16 而不是 bfloat16\n",
    "    llm_int8_enable_fp32_cpu_offload=True  # 启用 CPU 卸载\n",
    ")\n",
    "\n",
    "# 4. 加载模型（启用梯度检查点）\n",
    "model = CustomLlavaModel.from_pretrained(\n",
    "    model_dir,\n",
    "    quantization_config=nf4_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,            # 使用 float16\n",
    ")\n",
    "\n",
    "\n",
    "# 6. 加载处理器并配置\n",
    "llava_processor = AutoProcessor.from_pretrained(\n",
    "    model_dir,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some test  for sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(llava_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['query_inputs'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=sample['query_inputs']['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss[600:610]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练-测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## micl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import _utils\n",
    "# 设置训练参数\n",
    "batch_size = 1\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "# 创建数据处理器实例\n",
    "data_processor = DataProcessor(\n",
    "    dataset=dataset,\n",
    "    processor=llava_processor,\n",
    "    device=model.device  # 使用模型的设备\n",
    ")\n",
    "# 使用DataLoader进行批处理\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data_processor,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_processor.collate_fn,\n",
    ")\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        # 获取输入\n",
    "        query_inputs = batch['query_inputs']\n",
    "        target_inputs = batch['target_inputs']\n",
    "\n",
    "        # 提取嵌入\n",
    "        q_i, q_t = model.extract_embedding(\n",
    "            input_ids=query_inputs['input_ids'],          # 使用字典访问方式\n",
    "            pixel_values=query_inputs['pixel_values'],    # 使用字典访问方式\n",
    "            attention_mask=query_inputs['attention_mask'] # 使用字典访问方式\n",
    "        )\n",
    "\n",
    "        t_i, t_t = model.extract_embedding(\n",
    "            input_ids=target_inputs['input_ids'],         # 使用字典访问方式\n",
    "            pixel_values=target_inputs['pixel_values'],   # 使用字典访问方式\n",
    "            attention_mask=target_inputs['attention_mask']# 使用字典访问方式\n",
    "        )\n",
    "\n",
    "        # 计算MICL损失\n",
    "        loss = model.micl_loss(q_i, q_t, t_i, t_t)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # 打印每个epoch的平均损失\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ez 取得表征txt/img向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n",
      "q_i shape: torch.Size([1, 4096])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import _utils\n",
    "# 设置训练参数\n",
    "batch_size = 1\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "# 创建数据处理器实例\n",
    "data_processor = DataProcessor(\n",
    "    dataset=dataset,\n",
    "    processor=llava_processor,\n",
    "    device=model.device  # 使用模型的设备\n",
    ")\n",
    "# 使用DataLoader进行批处理\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data_processor,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_processor.collate_fn,\n",
    ")\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        # 获取输入\n",
    "        query_inputs = batch['query_inputs']\n",
    "        target_inputs = batch['target_inputs']\n",
    "\n",
    "        # 提取嵌入\n",
    "        q_i, q_t = model.extract_embedding(\n",
    "            input_ids=query_inputs['input_ids'],          # 使用字典访问方式\n",
    "            pixel_values=query_inputs['pixel_values'],    # 使用字典访问方式\n",
    "            attention_mask=query_inputs['attention_mask'] # 使用字典访问方式\n",
    "        )\n",
    "\n",
    "        t_i, t_t = model.extract_embedding(\n",
    "            input_ids=target_inputs['input_ids'],         # 使用字典访问方式\n",
    "            pixel_values=target_inputs['pixel_values'],   # 使用字典访问方式\n",
    "            attention_mask=target_inputs['attention_mask']# 使用字典访问方式\n",
    "        )\n",
    "\n",
    "        print(\"q_i shape:\", q_i.shape)\n",
    "        # ... 其余训练代码 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
